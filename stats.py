import os
import re
import glob
from collections import Counter, defaultdict
from itertools import combinations
import statistics

# --- è¨­å®š ---
DATA_DIR = '.' 

def get_files_by_year(directory):
    """
    Returns a dictionary: {'2024': ['2024-01-01', ...], '2025': ...}
    """
    files = glob.glob(os.path.join(directory, "????-??-??.txt"))
    year_map = defaultdict(list)
    
    for f in files:
        basename = os.path.basename(f)
        if re.match(r'\d{4}-\d{2}-\d{2}\.txt$', basename):
            date_str = basename.replace('.txt', '')
            year = date_str.split('-')[0]
            year_map[year].append(date_str)
            
    for year in year_map:
        year_map[year].sort()
        
    return dict(sorted(year_map.items()))

def normalize_name(raw_name):
    # ç§»é™¤é–‹é ­çš„æ•¸å­— (e.g., "1. ")
    clean = re.sub(r'^\d+\.\s+', '', raw_name.strip())
    return clean

def get_host_handle(name_str):
    # åˆ¤æ–·æ˜¯èª°å¸¶çš„æœ‹å‹
    match = re.search(r'\((@[\w_.]+)\)', name_str)
    if match: return match.group(1)
    if name_str.startswith('@'): return name_str
    return None

def calculate_streaks(all_session_dates, attendance_map):
    """
    è¨ˆç®—ç›®å‰çš„é€£çºŒå‡ºå¸­é€±æ•¸ (Current Streak)
    """
    current_streaks = {}
    all_people = set()
    for ppl in attendance_map.values():
        all_people.update(ppl)
        
    sorted_dates = sorted(all_session_dates, reverse=True)
    
    for person in all_people:
        streak = 0
        for date in sorted_dates:
            if person in attendance_map[date]:
                streak += 1
            else:
                break 
        current_streaks[person] = streak
        
    return current_streaks

def analyze_year(year, dates):
    print(f"\n{'='*12} ğŸ¸ {year} ç¾½çƒç¾¤å¹´åº¦å›é¡§ ğŸ¸ {'='*12}")
    print(f"çµ±è¨ˆæœŸé–“ï¼šå…± {len(dates)} æ¬¡æ‰“çƒæ´»å‹•\n")

    attendance_map = defaultdict(list)
    signup_positions = defaultdict(list)
    on_duty_counts = Counter()
    
    # è§£ææª”æ¡ˆ
    for date in dates:
        # 1. å ±ååå–®
        signup_path = os.path.join(DATA_DIR, f"{date}.txt")
        if os.path.exists(signup_path):
            with open(signup_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip() and re.match(r'^\d+\.', line):
                        # æŠ“å–å ±åé †åº
                        pos_match = re.match(r'^(\d+)\.', line)
                        position = int(pos_match.group(1))
                        
                        name = normalize_name(line)
                        attendance_map[date].append(name)
                        signup_positions[name].append(position)

        # 2. å€¼æ—¥ç”Ÿåå–®
        output_path = os.path.join(DATA_DIR, f"{date}-output.txt")
        if os.path.exists(output_path):
            with open(output_path, 'r', encoding='utf-8') as f:
                for line in f:
                    match = re.search(r':\d{2}.*:\s+(.+?)\s+\+\s+(.+?)$', line)
                    if match:
                        p1, p2 = match.group(1).strip(), match.group(2).strip()
                        on_duty_counts[p1] += 1
                        on_duty_counts[p2] += 1

    # --- é–‹å§‹è¨ˆç®—å„é …æ•¸æ“š ---

    # 1. å‡ºå¸­ç¸½æ•¸
    total_attendance = Counter()
    for attendees in attendance_map.values():
        total_attendance.update(attendees)

    # 2. æªåœ˜ç‹
    promoters = Counter()
    for name in total_attendance.keys():
        host = get_host_handle(name)
        if host and host != name:
            promoters[host] += total_attendance[name]

    # 3. é»è¸¢è¸¢ CP (è¨ˆç®—åŒæ™‚å‡ºå¸­çš„æ¬¡æ•¸)
    social_pairs = Counter()
    for attendees in attendance_map.values():
        # æ’åºä»¥ç¢ºä¿ A+B å’Œ B+A è¦–ç‚ºåŒä¸€çµ„
        sorted_attendees = sorted(attendees)
        for pair in combinations(sorted_attendees, 2):
            social_pairs[pair] += 1

    # 4. å€¼æ—¥ç”Ÿæ©Ÿç‡ (è‡³å°‘å‡ºå¸­ 3 æ¬¡æ‰åˆ—å…¥)
    ratios = []
    for person, attended in total_attendance.items():
        if attended >= 3:
            duties = on_duty_counts[person]
            ratio = (duties / attended) * 100
            ratios.append((person, attended, duties, ratio))
    
    most_likely_duty = sorted(ratios, key=lambda x: x[3], reverse=True)
    least_likely_duty = sorted(ratios, key=lambda x: x[3])

    # 5. æ‰‹é€Ÿæ’è¡Œ (å¹³å‡å ±åé †ä½) - è‡³å°‘å‡ºå¸­ 3 æ¬¡
    speed_stats = []
    for person, positions in signup_positions.items():
        if len(positions) >= 3:
            avg_pos = statistics.mean(positions)
            speed_stats.append((person, avg_pos))
            
    fastest_fingers = sorted(speed_stats, key=lambda x: x[1])
    slow_pokes = sorted(speed_stats, key=lambda x: x[1], reverse=True)

    # 6. é€£çºŒå‡ºå¸­ (Current Streak)
    streaks = calculate_streaks(dates, attendance_map)
    sorted_streaks = sorted(streaks.items(), key=lambda x: x[1], reverse=True)

    # --- è¼¸å‡ºçµæœ (å°ç£é„‰æ°‘é¢¨æ¨™é¡Œ) ---

    def print_list(emoji, title, items, formatter):
        print(f"\n{emoji} {title}")
        print("-" * 40)
        for i, item in enumerate(items[:5], 1):
            print(f"{i}. {formatter(item)}")

    # 1. å‡ºå¸­ç‹
    print_list("ğŸŸï¸", "çƒå ´åœ°ç¸›éˆ (å‡ºå¸­æ¬¡æ•¸æœ€å¤š)", 
               total_attendance.most_common(), 
               lambda x: f"{x[0]}: {x[1]} æ¬¡")

    # 2. é€£çºŒå‡ºå¸­
    print_list("ğŸ”¥", "é¢¨é›¨ç„¡é˜»å…¨å‹¤ç (ç›®å‰é€£çºŒå‡ºå¸­)", 
               [s for s in sorted_streaks if s[1] > 1], 
               lambda x: f"{x[0]}: é€£çºŒ {x[1]} é€±")

    # 3. æ‰‹é€Ÿæœ€å¿«
    print_list("âš¡", "å–®èº«äºŒåå¹´çš„æ‰‹é€Ÿ (å¹³å‡å ±åé †ä½)", 
               fastest_fingers, 
               lambda x: f"{x[0]}: å¹³å‡ç¬¬ {x[1]:.1f} é †ä½")
    
    # 4. æ‰‹é€Ÿæœ€æ…¢
    print_list("ğŸ¢", "å¿ƒè‡Ÿæœ€å¤§é¡†å£“ç·šç‹ (æœ€æ™šå ±å)", 
               slow_pokes, 
               lambda x: f"{x[0]}: å¹³å‡ç¬¬ {x[1]:.1f} é †ä½")

    # 5. å€¼æ—¥ç”Ÿç‹ (è¡°)
    print_list("ğŸ§¹", "å‘½ä¸­æ³¨å®šå€¼æ—¥ç”Ÿ (è¢«æŠ½ä¸­æ©Ÿç‡æœ€é«˜)", 
               most_likely_duty, 
               lambda x: f"{x[0]}: {x[3]:.1f}% ({x[2]}/{x[1]} æ¬¡)")

    # 6. é–ƒèº²ç‹ (é‹æ°£å¥½)
    print_list("ğŸŒŸ", "å¤©å…¬ä¼¯æœ‰ä¿åº‡ (è¢«æŠ½ä¸­æ©Ÿç‡æœ€ä½)", 
               least_likely_duty, 
               lambda x: f"{x[0]}: {x[3]:.1f}% ({x[2]}/{x[1]} æ¬¡)")

    # 7. CP æ¦œ (ç‰¹æ®Šéæ¿¾é‚è¼¯)
    print(f"\nğŸ’– é»è¸¢è¸¢ CP (æœ€å¸¸ä¸€èµ·å‡ºç¾çš„çµ„åˆ)")
    print("-" * 40)
    
    seen_people = set()
    count = 0
    # å¾æœ€å¸¸å‡ºç¾çš„ pair é–‹å§‹éæ­·
    for pair, freq in social_pairs.most_common():
        p1, p2 = pair
        # å¦‚æœé€™å° CP çš„ä»»ä½•ä¸€äººå·²ç¶“åœ¨æ¦œå–®ä¸Šäº†ï¼Œå°±è·³é (é¿å… A è·Ÿ B, A è·Ÿ C é‡è¤‡å‡ºç¾)
        if p1 not in seen_people and p2 not in seen_people:
            count += 1
            print(f"{count}. {p1} & {p2}: {freq} æ¬¡")
            seen_people.add(p1)
            seen_people.add(p2)
            
            if count >= 5: # åªå–å‰ 5 å°
                break

    # 8. æªåœ˜ç‹
    if promoters:
        print_list("ğŸ“¢", "æœ€å¼·æªåœ˜ç‹ (å¸¶æœ€å¤šæœ‹å‹)", 
                   promoters.most_common(), 
                   lambda x: f"{x[0]}: {x[1]} äºº")

def main():
    years_data = get_files_by_year(DATA_DIR)
    
    if not years_data:
        print("æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆï¼Œè«‹ç¢ºèªç›®éŒ„ä¸‹æ˜¯å¦æœ‰ YYYY-MM-DD.txt æ ¼å¼çš„æª”æ¡ˆã€‚")
        return

    for year, dates in years_data.items():
        analyze_year(year, dates)
        print("\n\n")

if __name__ == "__main__":
    main()
